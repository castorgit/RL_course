{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccb67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "import pygame\n",
    "import session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7603e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RussellsGridEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"ansi\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super(RussellsGridEnv, self).__init__()\n",
    "\n",
    "        # Define the grid size\n",
    "        self.height = 3\n",
    "        self.width = 4\n",
    "        self._nrow = 3\n",
    "        self._ncol = 4\n",
    "\n",
    "        # Define the action space\n",
    "        self.action_space = spaces.Discrete(4)  # Up, Right, Down, Left\n",
    "\n",
    "        # Define the observation space\n",
    "        self.observation_space = spaces.Discrete(self.height * self.width)\n",
    "\n",
    "        # Define the grid\n",
    "        self.grid = np.zeros((self.height, self.width))\n",
    "        self.grid[0, 3] = 1  # Green (terminal state)\n",
    "        self.grid[1, 3] = 2  # Red (terminal state)\n",
    "        self.grid[1, 1] = 3  # Black (impossible state)\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # For rendering\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "    @property\n",
    "    def nrow(self):\n",
    "        return self._nrow\n",
    "    @property\n",
    "    def ncol(self):\n",
    "        return self._ncol\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.state = 8  # Start at (0, 0)\n",
    "        \n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        row, col = divmod(self.state, self.width)\n",
    "\n",
    "        # Determine movement\n",
    "        if np.random.random() < 0.8:  # 80% chance of intended movement\n",
    "            if action == 0:  # Up\n",
    "                row = max(0, row - 1)\n",
    "            elif action == 1:  # Right\n",
    "                col = min(self.width - 1, col + 1)\n",
    "            elif action == 2:  # Down\n",
    "                row = min(self.height - 1, row + 1)\n",
    "            elif action == 3:  # Left\n",
    "                col = max(0, col - 1)\n",
    "        else:  # 20% chance of random adjacent movement\n",
    "            directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
    "            dr, dc = directions[np.random.randint(4)]\n",
    "            row = max(0, min(self.height - 1, row + dr))\n",
    "            col = max(0, min(self.width - 1, col + dc))\n",
    "\n",
    "        # Check if new state is valid\n",
    "        if self.grid[row, col] != 3:  # Not the black cell\n",
    "            self.state = row * self.width + col\n",
    "\n",
    "        # Check for terminal states\n",
    "        done = self.grid[row, col] in [1, 2]\n",
    "        reward = 1 if self.grid[row, col] == 1 else (-1 if self.grid[row, col] == 2 else -0.04)\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return self.state, reward, done, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "        if self.render_mode == \"ansi\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.render_mode == \"human\":\n",
    "            return self._render_human()\n",
    "        elif self.render_mode == \"ansi\":\n",
    "            return self._render_ansi()\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "            return self._render_rgb_array()\n",
    "\n",
    "    def _render_human(self):\n",
    "        if self.window is None:\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.width * 100, self.height * 100))\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.width * 100, self.height * 100))\n",
    "        canvas.fill((255, 255, 255))\n",
    "\n",
    "        pix_square_size = 100  # The size of a single grid square in pixels\n",
    "\n",
    "        # Draw the grid\n",
    "        for i in range(self.height):\n",
    "            for j in range(self.width):\n",
    "                if self.grid[i, j] == 1:\n",
    "                    color = (0, 255, 0)  # Green\n",
    "                elif self.grid[i, j] == 2:\n",
    "                    color = (255, 0, 0)  # Red\n",
    "                elif self.grid[i, j] == 3:\n",
    "                    color = (0, 0, 0)  # Black\n",
    "                else:\n",
    "                    color = (200, 200, 200)  # Light gray\n",
    "                pygame.draw.rect(\n",
    "                    canvas,\n",
    "                    color,\n",
    "                    pygame.Rect(\n",
    "                        pix_square_size * j,\n",
    "                        pix_square_size * i,\n",
    "                        pix_square_size,\n",
    "                        pix_square_size,\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        # Draw the agent\n",
    "        agent_row, agent_col = divmod(self.state, self.width)\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),  # Blue\n",
    "            (agent_col * pix_square_size + pix_square_size // 2, agent_row * pix_square_size + pix_square_size // 2),\n",
    "            pix_square_size // 3,\n",
    "        )\n",
    "\n",
    "        # Add gridlines\n",
    "        for x in range(self.width + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.height * pix_square_size),\n",
    "                width=3,\n",
    "            )\n",
    "        for y in range(self.height + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * y),\n",
    "                (self.width * pix_square_size, pix_square_size * y),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        self.window.blit(canvas, canvas.get_rect())\n",
    "        pygame.event.pump()\n",
    "        pygame.display.update()\n",
    "\n",
    "        self.clock.tick(self.metadata[\"render_fps\"])\n",
    "\n",
    "    def _render_ansi(self):\n",
    "        output = \"\"\n",
    "        for i in range(self.height):\n",
    "            for j in range(self.width):\n",
    "                if i * self.width + j == self.state:\n",
    "                    output += \"A \"\n",
    "                elif self.grid[i, j] == 1:\n",
    "                    output += \"G \"\n",
    "                elif self.grid[i, j] == 2:\n",
    "                    output += \"R \"\n",
    "                elif self.grid[i, j] == 3:\n",
    "                    output += \"B \"\n",
    "                else:\n",
    "                    output += \". \"\n",
    "            output += \"\\n\"\n",
    "            \n",
    "        print(output)\n",
    "        return 'null'\n",
    "\n",
    "    def _render_rgb_array(self):\n",
    "        \n",
    "        canvas = np.zeros((self.height * 100, self.width * 100, 3), dtype=np.uint8)\n",
    "\n",
    "        pix_square_size = 100  # The size of a single grid square in pixels\n",
    "\n",
    "        # Draw the grid\n",
    "        for i in range(self.height):\n",
    "            for j in range(self.width):\n",
    "                if self.grid[i, j] == 1:\n",
    "                    color = [0, 255, 0]  # Green\n",
    "                elif self.grid[i, j] == 2:\n",
    "                    color = [255, 0, 0]  # Red\n",
    "                elif self.grid[i, j] == 3:\n",
    "                    color = [0, 0, 0]  # Black\n",
    "                else:\n",
    "                    color = [200, 200, 200]  # Light gray\n",
    "                canvas[i*pix_square_size:(i+1)*pix_square_size, j*pix_square_size:(j+1)*pix_square_size] = color\n",
    "\n",
    "        # Draw the agent\n",
    "        agent_row, agent_col = divmod(self.state, self.width)\n",
    "        rr, cc = np.ogrid[\n",
    "            (agent_row * pix_square_size + pix_square_size // 2 - pix_square_size // 3):\n",
    "            (agent_row * pix_square_size + pix_square_size // 2 + pix_square_size // 3),\n",
    "            (agent_col * pix_square_size + pix_square_size // 2 - pix_square_size // 3):\n",
    "            (agent_col * pix_square_size + pix_square_size // 2 + pix_square_size // 3)\n",
    "        ]\n",
    "        canvas[rr, cc] = [0, 0, 255]  # Blue\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "# Register the environment\n",
    "gym.register(\n",
    "    id='RussellsGrid-v0',\n",
    "    entry_point='__main__:RussellsGridEnv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ef9980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Activity 1 - One Random Episode\n",
    "\"\"\"\n",
    "#[Write your Code Here]\n",
    "\n",
    "env = gym.make('RussellsGrid-v0', render_mode = 'human')\n",
    "env.reset()\n",
    "\n",
    "[YOUR CODE HERE]\n",
    "\n",
    "print(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17dc2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.44\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Activity 2 - Total Reward in an episode\n",
    "    Calculate the total reward based on the previous calculated list\n",
    "\"\"\"\n",
    "#[Write your Code Here]\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8272382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3139852372238505\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Activity 3 - Total Reward in an episode with GAMMA\n",
    "    Calculate the total reward based on the previous calculated list but with gamma decay\n",
    "    use gamma as 0.99\n",
    "\"\"\"\n",
    "#[Write your Code Here]\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7068ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean -1.5497360000000004 std 1.3885486848879305\n",
      "mean -1.2123355694298212 std 0.9051925072059508\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Activity 4 - Long Term reward \n",
    "    \n",
    "    Create a function to calculate long term reward with gamma as parameter and number of iterations\n",
    "    remember gamma 1 no decay, gamma <1 decay\n",
    "\n",
    "\"\"\"\n",
    "def execute_env(gamma, eps=10):\n",
    "    lt_reward = []\n",
    "#[Write your Code Here]\n",
    "\n",
    "lt_reward_no_decay = execute_env(1, 10000)\n",
    "print ('mean', np.mean(lt_reward_no_decay), 'std', np.std(lt_reward_no_decay))\n",
    "\n",
    "lt_reward_decay = execute_env(0.99, 10000)\n",
    "print ('mean', np.mean(lt_reward_decay), 'std', np.std(lt_reward_decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3729788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Activity 5 - Policy\n",
    "    \n",
    "    Create a Policy P that you think is optimal.\n",
    "    Remember Policy is the treasure map\n",
    "    Just create an array P that has all the right actions\n",
    "    Remember actions = 0, 1, 2, 3 which are UP, RIGHT, DOWN, LEFT\n",
    "    \n",
    "    0  1  2  3            [0,0] [0,1] [0,2] [0,3]\n",
    "    4  5  6  7            [1,0] [1,1] [1,2] [1,3]\n",
    "    8  9  10 11           [2,0] [2,1] [2,2] [2,3]\n",
    "    \n",
    "    P[0,0] = 1 # Right\n",
    "    P[0,1] = 1 # Right\n",
    "    P[0,2] = 1 # Right\n",
    "    \n",
    "    Then use the policy to move in the environment\n",
    "\n",
    "\"\"\"\n",
    "P=np.zeros((3, 4))\n",
    "\n",
    "P[0,0]=1\n",
    "P[0,1]=1\n",
    "#[Write your Code Here]\n",
    "\n",
    "def one_episode_my_policy(P, render=False):\n",
    "#[CODE HERE] Activity 2.3 Optimal Policy\n",
    "  \"\"\"\n",
    "    The function \"one_episode_my_policy\" runs an episode according to the policy defined in table 'P'\n",
    "    and returns a list of rewards obtained during the episode.\n",
    "\n",
    "    :param render: The \"render\" parameter is a boolean flag that determines whether or not to render the\n",
    "    environment during the episode. If set to True, the environment will be visually displayed as the\n",
    "    episode progresses. If set to False, the environment will not be rendered, defaults to False\n",
    "    (optional)\n",
    "    :return: a list of rewards obtained during a random episode in the environment.\n",
    "  \"\"\"\n",
    "#[Write your Code Here]\n",
    "print(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f82a1255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value Optimal Policy Format (3x4):\n",
      "--------------------------------------------------\n",
      "→ → → G \n",
      "↑ X ↑ N \n",
      "↑ ← ↑ ← \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Activity 5 - Print Policy\n",
    "    \n",
    "    Print your Policy\n",
    "    use this symbols actions = ['↑', '→', '↓', '←']\n",
    "    Use the function in the Assignment description\n",
    "\"\"\"\n",
    "\n",
    "def print_policy(env, policy):\n",
    "    \"\"\"Prints the policy in a grid format.\"\"\"\n",
    "    \n",
    "    ncol = env.unwrapped.ncol\n",
    "    nrow = env.unwrapped.nrow\n",
    "    \n",
    "    print(\"\\nValue Optimal Policy Format (3x4):\")\n",
    "    print(\"-\" * 50)\n",
    "    actions = ['↑', '→', '↓', '←']\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            s = i * ncol + j\n",
    "            if (i, j) == (1,1):\n",
    "                print('X', end=' ')\n",
    "            elif (i,j) == (0,3):\n",
    "                print('G', end=' ')\n",
    "            elif (i,j) == (1,3):\n",
    "                print('N', end=' ')\n",
    "            else:\n",
    "                a = int(policy[i,j])\n",
    "                print(actions[a], end=' ')\n",
    "        print()\n",
    "\n",
    "env.reset()   \n",
    "#[Write your Code Here]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa726f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "gymnasium           1.0.0\n",
      "numpy               1.26.4\n",
      "pygame              2.6.0\n",
      "session_info        1.0.0\n",
      "-----\n",
      "IPython             8.26.0\n",
      "jupyter_client      8.6.2\n",
      "jupyter_core        5.7.2\n",
      "-----\n",
      "Python 3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0]\n",
      "Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
      "-----\n",
      "Session information updated at 2025-04-02 17:55\n"
     ]
    }
   ],
   "source": [
    "session_info.show(html=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
