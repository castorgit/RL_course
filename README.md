# Examples Course Introduction to Reinforcement Learning

Repository with Examples and Exercises for an Introuductory Reinforcement Learning Course. Based on the Sutton/Barto Textbook 
and David Silver RL course

The files in this repository are based on Gymnasium (farama foundation) and KERAS (for Deep Reinforcement Learning) <br>
Some examples are build with Pytorch as well <br>

They are kept as simple as possible for educational purposes

They are not created to beat any score, but to compare and learn the differences between the approaches.

Notebooks classification structure

00 : Basic environment creation / Setup \
015 : Dynamic Programming           \
018 : Monte-Carlo                   \
019 : TD(0) algorithms              \
020 : SARSA                         \
021 : Q-Learning                    

... Value Based Metods ....         

021 : Q-Learning                    \
030 : DQN - Deep Q-Network          \
031 : DDQN - Double Deep Q-Network  \
032 : D3QN - Duelling Q-Networks    \
033 : PER - Prioritized Experience Replay \

... Policy Based Methods...

035 : PPO - Proximal Policy Optimization   \
040 : A2C - Actor Critic                  \
050 : REINFORCE                     \
060 : TD3 - Twin Critic             \
070 : SAC - Soft Actor Critic       \
...                                 \
080 : Heuristics                    \
...                                 \
090 : LLM-Agents                    \
...                                 \
100 : Torch/ KERAS Neural Network examples  

---- Stable Baselines 3 examples ....

135 : PPO SB3 - Proximal Policy Optimization with Stable Baselines 3  \
140 : A2C SB3 - Actor Critic with Stable Baselines 3                  \
160 : TD3 SB3 - Twin Critics with Stable Baselines 3                  \
170 : SAC SB3 - Soft Actor Critic with Stable Baselines 3             \
\
All Notebooks can be used under a MIT License, if not stated differently in the code. 
Some examples may be inspired in open sourced material.
