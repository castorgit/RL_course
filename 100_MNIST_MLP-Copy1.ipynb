{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebddc4d",
   "metadata": {},
   "source": [
    "#### **MNIST MLP with pytorch**\n",
    "\n",
    "This is a template of an MNIST classifier with an Artificial Neural Network (MLP)\n",
    "If follows the basic blocks of a Deep Learning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366ae7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9298d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device GPU configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_classes = 10  # Digits 0-9\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72ef22",
   "metadata": {},
   "source": [
    "#### **Reading MNIST Dataset**\n",
    "Most frameworks offer an easy way to download the MNIST dataset. In this case we use the datasets method\n",
    "\n",
    "PyTorch models expect input data in the form of tensors because tensors are the fundamental data structure in this framework for computation.\n",
    "\n",
    "You can see below the variable **images** is a tensor and this variable contains all the data to be feed to the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3556bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(), \n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daed1920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef3cfa",
   "metadata": {},
   "source": [
    "#### **ANN architecture definition**\n",
    "This is the key part of the notebook, in this cell we define the structure of the network \n",
    "and all the different elements mainly\n",
    "\n",
    "- Activation function \n",
    "- Layer size\n",
    "- Number of layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7be580",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "input_size = 784  # 28x28 images\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, input_size)  # Flatten the image\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    " \n",
    "model = NeuralNet(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c18650",
   "metadata": {},
   "source": [
    "#### **Network training**\n",
    "In this training the network is trained with the data from the MNIST we have prepared previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f7464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2600\n",
      "Epoch [1/5], Step [200/600], Loss: 0.4031\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2388\n",
      "Epoch [1/5], Step [400/600], Loss: 0.2919\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1596\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1626\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1115\n",
      "Epoch [2/5], Step [200/600], Loss: 0.2196\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0917\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0878\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1990\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1687\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0818\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0657\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0653\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0906\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0771\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0309\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0536\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0292\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0877\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0242\n",
      "Epoch [4/5], Step [500/600], Loss: 0.1740\n",
      "Epoch [4/5], Step [600/600], Loss: 0.1817\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0314\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0447\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0915\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0135\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0254\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0369\n",
      "Accuracy of the network on the 10000 test images: 97.67%\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Testing the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c64b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the variable images is a  <class 'torch.Tensor'>  with a dimension of  torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"the variable images is a \", type(images), \" with a dimension of \", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe1ba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac340e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Loss and Accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff220a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
